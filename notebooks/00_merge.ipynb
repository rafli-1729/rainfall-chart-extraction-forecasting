{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f4b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca9e988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Highest 30 Min Rainfall (mm)</th>\n",
       "      <th>Highest 60 Min Rainfall (mm)</th>\n",
       "      <th>Highest 120 Min Rainfall (mm)</th>\n",
       "      <th>Mean Temperature (Â°C)</th>\n",
       "      <th>Maximum Temperature (Â°C)</th>\n",
       "      <th>Minimum Temperature (Â°C)</th>\n",
       "      <th>Mean Wind Speed (km/h)</th>\n",
       "      <th>Max Wind Speed (km/h)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Highest 30 Min Rainfall (mm) Highest 60 Min Rainfall (mm)  \\\n",
       "0  2009-01-01                            Â—                            Â—   \n",
       "1  2009-01-02                            Â—                            Â—   \n",
       "2  2009-01-03                            Â—                            Â—   \n",
       "3  2009-01-04                            Â—                            Â—   \n",
       "4  2009-01-05                            Â—                            Â—   \n",
       "\n",
       "  Highest 120 Min Rainfall (mm) Mean Temperature (Â°C)  \\\n",
       "0                             Â—                     Â—   \n",
       "1                             Â—                     Â—   \n",
       "2                             Â—                     Â—   \n",
       "3                             Â—                     Â—   \n",
       "4                             Â—                     Â—   \n",
       "\n",
       "  Maximum Temperature (Â°C) Minimum Temperature (Â°C) Mean Wind Speed (km/h)  \\\n",
       "0                        Â—                        Â—                      Â—   \n",
       "1                        Â—                        Â—                      Â—   \n",
       "2                        Â—                        Â—                      Â—   \n",
       "3                        Â—                        Â—                      Â—   \n",
       "4                        Â—                        Â—                      Â—   \n",
       "\n",
       "  Max Wind Speed (km/h)  \n",
       "0                     Â—  \n",
       "1                     Â—  \n",
       "2                     Â—  \n",
       "3                     Â—  \n",
       "4                     Â—  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_data_training = '../data/raw/Train/Admiralty/Data_Gabungan_Lainnya_2009.csv'\n",
    "contoh = pd.read_csv(link_data_training)\n",
    "contoh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "003ede2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai proses otomatis untuk semua lokasi...\n",
      "Folder output dipastikan ada di: ../data/merged/\n",
      "Ditemukan 44 folder lokasi untuk diproses.\n",
      "\n",
      "-> Memproses: 'Admiralty'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Admiralty_merged.csv'\n",
      "\n",
      "-> Memproses: 'Ang_Mo_Kio'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Ang_Mo_Kio_merged.csv'\n",
      "\n",
      "-> Memproses: 'Bukit_Panjang'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Bukit_Panjang_merged.csv'\n",
      "\n",
      "-> Memproses: 'Bukit_Timah'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Bukit_Timah_merged.csv'\n",
      "\n",
      "-> Memproses: 'Buona_Vista'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Buona_Vista_merged.csv'\n",
      "\n",
      "-> Memproses: 'Changi'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Changi_merged.csv'\n",
      "\n",
      "-> Memproses: 'Choa_Chu_Kang_Central'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Choa_Chu_Kang_Central_merged.csv'\n",
      "\n",
      "-> Memproses: 'Choa_Chu_Kang_South'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Choa_Chu_Kang_South_merged.csv'\n",
      "\n",
      "-> Memproses: 'Clementi'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Clementi_merged.csv'\n",
      "\n",
      "-> Memproses: 'East_Coast_Parkway'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'East_Coast_Parkway_merged.csv'\n",
      "\n",
      "-> Memproses: 'Jurong_Island'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Jurong_Island_merged.csv'\n",
      "\n",
      "-> Memproses: 'Jurong_Pier'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Jurong_Pier_merged.csv'\n",
      "\n",
      "-> Memproses: 'Jurong_West'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Jurong_West_merged.csv'\n",
      "\n",
      "-> Memproses: 'Kent_Ridge'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Kent_Ridge_merged.csv'\n",
      "\n",
      "-> Memproses: 'Kranji_Reservoir'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Kranji_Reservoir_merged.csv'\n",
      "\n",
      "-> Memproses: 'Lim_Chu_Kang'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Lim_Chu_Kang_merged.csv'\n",
      "\n",
      "-> Memproses: 'Lower_Peirce_Reservoir'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Lower_Peirce_Reservoir_merged.csv'\n",
      "\n",
      "-> Memproses: 'Macritchie_Reservoir'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Macritchie_Reservoir_merged.csv'\n",
      "\n",
      "-> Memproses: 'Mandai'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Mandai_merged.csv'\n",
      "\n",
      "-> Memproses: 'Marina_Barrage'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Marina_Barrage_merged.csv'\n",
      "\n",
      "-> Memproses: 'Marine_Parade'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Marine_Parade_merged.csv'\n",
      "\n",
      "-> Memproses: 'Newton'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Newton_merged.csv'\n",
      "\n",
      "-> Memproses: 'Nicoll_Highway'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Nicoll_Highway_merged.csv'\n",
      "\n",
      "-> Memproses: 'Pasir_Panjang'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Pasir_Panjang_merged.csv'\n",
      "\n",
      "-> Memproses: 'Pasir_Ris_Central'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Pasir_Ris_Central_merged.csv'\n",
      "\n",
      "-> Memproses: 'Pasir_Ris_West'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Pasir_Ris_West_merged.csv'\n",
      "\n",
      "-> Memproses: 'Paya_Lebar'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Paya_Lebar_merged.csv'\n",
      "\n",
      "-> Memproses: 'Pulau_Ubin'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Pulau_Ubin_merged.csv'\n",
      "\n",
      "-> Memproses: 'Punggol'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Punggol_merged.csv'\n",
      "\n",
      "-> Memproses: 'Queenstown'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Queenstown_merged.csv'\n",
      "\n",
      "-> Memproses: 'Seletar'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Seletar_merged.csv'\n",
      "\n",
      "-> Memproses: 'Sembawang'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Sembawang_merged.csv'\n",
      "\n",
      "-> Memproses: 'Sentosa_Island'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Sentosa_Island_merged.csv'\n",
      "\n",
      "-> Memproses: 'Simei'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Simei_merged.csv'\n",
      "\n",
      "-> Memproses: 'Somerset_Road'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Somerset_Road_merged.csv'\n",
      "\n",
      "-> Memproses: 'Tai_Seng'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Tai_Seng_merged.csv'\n",
      "\n",
      "-> Memproses: 'Tanjong_Katong'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Tanjong_Katong_merged.csv'\n",
      "\n",
      "-> Memproses: 'Tengah'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Tengah_merged.csv'\n",
      "\n",
      "-> Memproses: 'Toa_Payoh'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Toa_Payoh_merged.csv'\n",
      "\n",
      "-> Memproses: 'Tuas'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Tuas_merged.csv'\n",
      "\n",
      "-> Memproses: 'Tuas_South'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Tuas_South_merged.csv'\n",
      "\n",
      "-> Memproses: 'Ulu_Pandan'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Ulu_Pandan_merged.csv'\n",
      "\n",
      "-> Memproses: 'Upper_Peirce_Reservoir'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Upper_Peirce_Reservoir_merged.csv'\n",
      "\n",
      "-> Memproses: 'Whampoa'...\n",
      "  -> Jumlah kolom setelah digabung: 9\n",
      "  âœ… Berhasil! Data dengan kolom bersih disimpan di: 'Whampoa_merged.csv'\n",
      "\n",
      "\n",
      "ðŸŽ‰ Semua proses selesai!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Path\n",
    "base_train_path = '../data/raw/Train'\n",
    "output_path = '../data/merged/'\n",
    "\n",
    "# Cleaning Column Name\n",
    "def clean_column_names(df):\n",
    "    \"\"\"\n",
    "    Membersihkan dan menyeragamkan nama kolom pada DataFrame.\n",
    "    \"\"\"\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        cleaned_col = col.strip().replace(' ', '_').lower()\n",
    "        cleaned_col = re.sub(r'[().%Â°]', '', cleaned_col)\n",
    "        new_columns.append(cleaned_col)\n",
    "    df.columns = new_columns\n",
    "    return df\n",
    "\n",
    "# Merge Dataset Each City\n",
    "def proses_semua_lokasi(path_induk, path_keluaran):\n",
    "    \"\"\"\n",
    "    Melakukan loop ke semua folder, menggabungkan CSV, membersihkan nama kolom,\n",
    "    dan menyimpan hasilnya.\n",
    "    \"\"\"\n",
    "    print(\"Memulai proses otomatis untuk semua lokasi...\")\n",
    "    os.makedirs(path_keluaran, exist_ok=True)\n",
    "    print(f\"Folder output dipastikan ada di: {path_keluaran}\")\n",
    "\n",
    "    try:\n",
    "        folder_lokasi = [f.name for f in os.scandir(path_induk) if f.is_dir()]\n",
    "        print(f\"Ditemukan {len(folder_lokasi)} folder lokasi untuk diproses.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ Error: Direktori induk tidak ditemukan di '{path_induk}'. Hentikan proses.\")\n",
    "        return\n",
    "\n",
    "    for nama_lokasi in folder_lokasi:\n",
    "        print(f\"\\n-> Memproses: '{nama_lokasi}'...\")\n",
    "\n",
    "        path_lokasi_spesifik = os.path.join(path_induk, nama_lokasi)\n",
    "        daftar_file_csv = sorted(glob.glob(os.path.join(path_lokasi_spesifik, \"*.csv\")))\n",
    "\n",
    "        if not daftar_file_csv:\n",
    "            print(f\"  -- Lewati '{nama_lokasi}', tidak ada file .csv ditemukan.\")\n",
    "            continue\n",
    "\n",
    "        # PENTING: Lakukan pembersihan nama kolom SEBELUM digabung\n",
    "        list_of_dfs = []\n",
    "        for file in daftar_file_csv:\n",
    "            df = pd.read_csv(file)\n",
    "            # Langsung bersihkan nama kolom setelah file dibaca\n",
    "            df = clean_column_names(df)\n",
    "            list_of_dfs.append(df)\n",
    "\n",
    "        # Gabungkan DataFrame yang nama kolomnya sudah seragam\n",
    "        df_gabungan = pd.concat(list_of_dfs, ignore_index=True)\n",
    "\n",
    "        # Cek jumlah kolom setelah digabung\n",
    "        print(f\"  -> Jumlah kolom setelah digabung: {len(df_gabungan.columns)}\")\n",
    "\n",
    "        nama_file_output = f\"{nama_lokasi}_merged.csv\"\n",
    "        path_file_output = os.path.join(path_keluaran, nama_file_output)\n",
    "\n",
    "        df_gabungan.to_csv(path_file_output, index=False)\n",
    "        print(f\"  âœ… Berhasil! Data dengan kolom bersih disimpan di: '{nama_file_output}'\")\n",
    "\n",
    "    print(\"\\n\\nðŸŽ‰ Semua proses selesai!\")\n",
    "\n",
    "# Running\n",
    "proses_semua_lokasi(base_train_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffdf0902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>highest_30_min_rainfall_mm</th>\n",
       "      <th>highest_60_min_rainfall_mm</th>\n",
       "      <th>highest_120_min_rainfall_mm</th>\n",
       "      <th>mean_temperature_c</th>\n",
       "      <th>maximum_temperature_c</th>\n",
       "      <th>minimum_temperature_c</th>\n",
       "      <th>mean_wind_speed_km/h</th>\n",
       "      <th>max_wind_speed_km/h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "      <td>Â—</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date highest_30_min_rainfall_mm highest_60_min_rainfall_mm  \\\n",
       "0  2009-01-01                          Â—                          Â—   \n",
       "1  2009-01-02                          Â—                          Â—   \n",
       "2  2009-01-03                          Â—                          Â—   \n",
       "3  2009-01-04                          Â—                          Â—   \n",
       "4  2009-01-05                          Â—                          Â—   \n",
       "\n",
       "  highest_120_min_rainfall_mm mean_temperature_c maximum_temperature_c  \\\n",
       "0                           Â—                  Â—                     Â—   \n",
       "1                           Â—                  Â—                     Â—   \n",
       "2                           Â—                  Â—                     Â—   \n",
       "3                           Â—                  Â—                     Â—   \n",
       "4                           Â—                  Â—                     Â—   \n",
       "\n",
       "  minimum_temperature_c mean_wind_speed_km/h max_wind_speed_km/h  \n",
       "0                     Â—                    Â—                   Â—  \n",
       "1                     Â—                    Â—                   Â—  \n",
       "2                     Â—                    Â—                   Â—  \n",
       "3                     Â—                    Â—                   Â—  \n",
       "4                     Â—                    Â—                   Â—  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admiralty_merged_path = '../data/merged/Admiralty_merged.csv'\n",
    "admiralty_merged = pd.read_csv(admiralty_merged_path)\n",
    "admiralty_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2459802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5448 entries, 0 to 5447\n",
      "Data columns (total 9 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   date                         5448 non-null   object\n",
      " 1   highest_30_min_rainfall_mm   5153 non-null   object\n",
      " 2   highest_60_min_rainfall_mm   5153 non-null   object\n",
      " 3   highest_120_min_rainfall_mm  5153 non-null   object\n",
      " 4   mean_temperature_c           5424 non-null   object\n",
      " 5   maximum_temperature_c        5424 non-null   object\n",
      " 6   minimum_temperature_c        5424 non-null   object\n",
      " 7   mean_wind_speed_km/h         5394 non-null   object\n",
      " 8   max_wind_speed_km/h          5395 non-null   object\n",
      "dtypes: object(9)\n",
      "memory usage: 383.2+ KB\n"
     ]
    }
   ],
   "source": [
    "admiralty_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2fac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re # Diperlukan untuk pembersihan nama kolom\n",
    "\n",
    "# --- PENGATURAN PATH ---\n",
    "base_train_path = '../data/raw/Test/'\n",
    "output_path = '../data/merged/Test/'\n",
    "\n",
    "# --- FUNGSI PEMBERSIH NAMA KOLOM ---\n",
    "def clean_column_names(df):\n",
    "    \"\"\"\n",
    "    Membersihkan dan menyeragamkan nama kolom pada DataFrame.\n",
    "    \"\"\"\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        cleaned_col = col.strip().replace(' ', '_').lower()\n",
    "        cleaned_col = re.sub(r'[().%Â°]', '', cleaned_col)\n",
    "        new_columns.append(cleaned_col)\n",
    "    df.columns = new_columns\n",
    "    return df\n",
    "\n",
    "# --- LOGIKA UTAMA ---\n",
    "def proses_semua_lokasi(path_induk, path_keluaran):\n",
    "    \"\"\"\n",
    "    Melakukan loop ke semua folder, menggabungkan CSV, membersihkan nama kolom,\n",
    "    dan menyimpan hasilnya.\n",
    "    \"\"\"\n",
    "    print(\"Memulai proses otomatis untuk semua lokasi...\")\n",
    "    os.makedirs(path_keluaran, exist_ok=True)\n",
    "    print(f\"Folder output dipastikan ada di: {path_keluaran}\")\n",
    "\n",
    "    try:\n",
    "        folder_lokasi = [f.name for f in os.scandir(path_induk) if f.is_dir()]\n",
    "        print(f\"Ditemukan {len(folder_lokasi)} folder lokasi untuk diproses.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ Error: Direktori induk tidak ditemukan di '{path_induk}'. Hentikan proses.\")\n",
    "        return\n",
    "\n",
    "    for nama_lokasi in folder_lokasi:\n",
    "        print(f\"\\n-> Memproses: '{nama_lokasi}'...\")\n",
    "\n",
    "        path_lokasi_spesifik = os.path.join(path_induk, nama_lokasi)\n",
    "        daftar_file_csv = sorted(glob.glob(os.path.join(path_lokasi_spesifik, \"*.csv\")))\n",
    "\n",
    "        if not daftar_file_csv:\n",
    "            print(f\"  -- Lewati '{nama_lokasi}', tidak ada file .csv ditemukan.\")\n",
    "            continue\n",
    "\n",
    "        # PENTING: Lakukan pembersihan nama kolom SEBELUM digabung\n",
    "        list_of_dfs = []\n",
    "        for file in daftar_file_csv:\n",
    "            df = pd.read_csv(file)\n",
    "            # Langsung bersihkan nama kolom setelah file dibaca\n",
    "            df = clean_column_names(df)\n",
    "            list_of_dfs.append(df)\n",
    "\n",
    "        # Gabungkan DataFrame yang nama kolomnya sudah seragam\n",
    "        df_gabungan = pd.concat(list_of_dfs, ignore_index=True)\n",
    "\n",
    "        # Cek jumlah kolom setelah digabung\n",
    "        print(f\"  -> Jumlah kolom setelah digabung: {len(df_gabungan.columns)}\")\n",
    "\n",
    "        nama_file_output = f\"{nama_lokasi}_gabungan_bersih.csv\"\n",
    "        path_file_output = os.path.join(path_keluaran, nama_file_output)\n",
    "\n",
    "        df_gabungan.to_csv(path_file_output, index=False)\n",
    "        print(f\"  âœ… Berhasil! Data dengan kolom bersih disimpan di: '{nama_file_output}'\")\n",
    "\n",
    "    print(\"\\n\\nðŸŽ‰ Semua proses selesai!\")\n",
    "\n",
    "# --- JALANKAN PROSES ---\n",
    "proses_semua_lokasi(base_train_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79735ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bukit_panjang_test = pd.read_csv('../data/merged/Test/Bukit_Panjang_gabungan_bersih.csv')\n",
    "bukit_panjang_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9090433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np # Import numpy untuk menggunakan np.nan\n",
    "\n",
    "# --- PENGATURAN PATH ---\n",
    "# Path utama ke folder Test Anda\n",
    "base_test_path = '../data/raw/Test/'\n",
    "# Path dan nama file untuk output final dataset test\n",
    "output_file = '../data/processed/test.csv'\n",
    "\n",
    "# --- FUNGSI PEMBERSIH NAMA KOLOM ---\n",
    "def clean_column_names(df):\n",
    "    \"\"\"Membersihkan dan menyeragamkan nama kolom pada DataFrame.\"\"\"\n",
    "    new_columns = []\n",
    "    for col in df.columns:\n",
    "        cleaned_col = col.strip().replace(' ', '_').lower()\n",
    "        cleaned_col = re.sub(r'[().%Â°/]', '', cleaned_col)\n",
    "        new_columns.append(cleaned_col)\n",
    "    df.columns = new_columns\n",
    "    return df\n",
    "\n",
    "# --- LOGIKA UTAMA ---\n",
    "def proses_data_test(path_induk, path_output):\n",
    "    \"\"\"\n",
    "    Menggabungkan semua file CSV dari folder Test, membersihkannya,\n",
    "    dan menambahkan kolom kosong untuk prediksi.\n",
    "    \"\"\"\n",
    "    print(\"Memulai proses pembuatan dataset test final...\")\n",
    "    try:\n",
    "        folder_lokasi = [f.name for f in os.scandir(path_induk) if f.is_dir()]\n",
    "        print(f\"Ditemukan {len(folder_lokasi)} folder lokasi untuk diproses.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ Error: Direktori Test tidak ditemukan di '{path_induk}'. Hentikan proses.\")\n",
    "        return\n",
    "\n",
    "    all_locations_data = []\n",
    "    for nama_lokasi in folder_lokasi:\n",
    "        print(f\"  -> Memproses: '{nama_lokasi}'...\")\n",
    "        path_lokasi_spesifik = os.path.join(path_induk, nama_lokasi)\n",
    "        daftar_file_csv = sorted(glob.glob(os.path.join(path_lokasi_spesifik, \"*.csv\")))\n",
    "        if not daftar_file_csv:\n",
    "            continue\n",
    "\n",
    "        list_of_dfs = []\n",
    "        for file in daftar_file_csv:\n",
    "            df = pd.read_csv(file)\n",
    "            df = clean_column_names(df)\n",
    "            list_of_dfs.append(df)\n",
    "\n",
    "        df_gabungan_lokasi = pd.concat(list_of_dfs, ignore_index=True)\n",
    "        df_gabungan_lokasi['lokasi'] = nama_lokasi\n",
    "        all_locations_data.append(df_gabungan_lokasi)\n",
    "\n",
    "    if not all_locations_data:\n",
    "        print(\"Tidak ada data yang berhasil diproses.\")\n",
    "        return\n",
    "\n",
    "    final_test_dataset = pd.concat(all_locations_data, ignore_index=True)\n",
    "\n",
    "    print(\"\\nMenyeragamkan tipe data...\")\n",
    "    kolom_untuk_diubah = [\n",
    "        'highest_30_min_rainfall_mm', 'highest_60_min_rainfall_mm',\n",
    "        'highest_120_min_rainfall_mm', 'mean_temperature_c',\n",
    "        'maximum_temperature_c', 'minimum_temperature_c',\n",
    "        'mean_wind_speed_km/h', 'max_wind_speed_km/h'\n",
    "    ]\n",
    "    for col in kolom_untuk_diubah:\n",
    "        if col in final_test_dataset.columns:\n",
    "            final_test_dataset[col] = pd.to_numeric(final_test_dataset[col], errors='coerce')\n",
    "\n",
    "    final_test_dataset['date'] = pd.to_datetime(final_test_dataset['date'])\n",
    "\n",
    "    # ==========================================================\n",
    "    # ===> TAMBAHKAN KOLOM KOSONG UNTUK PREDIKSI <===\n",
    "    # ==========================================================\n",
    "    final_test_dataset['daily_rainfall_total_mm'] = np.nan\n",
    "    print(\"-> Kolom 'daily_rainfall_total_mm' kosong berhasil ditambahkan.\")\n",
    "\n",
    "    # 4. Simpan dataset final\n",
    "    final_test_dataset.to_csv(path_output, index=False)\n",
    "\n",
    "    print(\"\\n\\nðŸŽ‰ Dataset test final berhasil dibuat!\")\n",
    "    print(f\"Disimpan di: {path_output}\")\n",
    "    print(\"\\n--- Informasi Dataset Final Test (dengan kolom prediksi) ---\")\n",
    "    final_test_dataset.info()\n",
    "\n",
    "# --- JALANKAN PROSES ---\n",
    "proses_data_test(base_test_path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged = pd.read_csv('../data/processed/test.csv')\n",
    "test_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6800b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged['date'] = pd.to_datetime(test_merged['date'])\n",
    "test_merged['tahun_bulan'] = test_merged['date'].dt.strftime('%Y-%m')\n",
    "test_merged['tahun_bulan'] = pd.to_datetime(test_merged['tahun_bulan'])\n",
    "test_merged = pd.merge(test_merged, external_features, on = 'tahun_bulan', how = 'left')\n",
    "\n",
    "test_merged.drop(columns = ['tahun_bulan'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e2cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
